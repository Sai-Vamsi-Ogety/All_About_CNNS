{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vanilla_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO-v1Ay-okvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy scipy scikit-learn pillow h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1_gBPqipA7b",
        "colab_type": "code",
        "outputId": "07914554-d5c3-4c17-b709-8c72c5659cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "source": [
        "# loading the dataset\n",
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVbh32VMpTwJ",
        "colab_type": "code",
        "outputId": "d7fe3137-c20c-445d-9cb7-959a2bdfd8ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(x_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVTqjMECpauj",
        "colab_type": "code",
        "outputId": "5bb5e195-5682-4e96-ba06-9238892ea54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfzWeVBmqtFS",
        "colab_type": "code",
        "outputId": "63241cfc-62e9-479d-8ce5-7f3bb99d6a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNzVn7R9pdek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshaping the numpy array into an image format\n",
        "def pre_process_images(x_train,y_train,x_test,y_test):\n",
        "  image_height,image_width = 28,28\n",
        "  x_train = x_train.reshape(x_train.shape[0], image_height, image_width, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], image_height, image_width, 1)\n",
        "  input_shape = (image_height, image_width, 1)\n",
        "  no_classes = 10\n",
        "  # changing to float\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  #scaling to [0,1]\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  # category encoding\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, no_classes)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, no_classes)\n",
        "  print(\"Pre_processing_done\")\n",
        "  return x_train,y_train,x_test,y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPM879ZZqSo4",
        "colab_type": "code",
        "outputId": "46293796-f8e8-415c-f274-054a042db2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwQSKNT9qU2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOH3P9iDseUO",
        "colab_type": "code",
        "outputId": "cd7e53bb-ea33-4c8e-9057-ded89ea9663e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oiRGIgJsgMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simple_cnn(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        activation='relu',\n",
        "        input_shape=input_shape\n",
        "    ))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "    model.add(tf.keras.layers.Dense(units=no_classes, activation='softmax'))\n",
        "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cms_9usC7XhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model():\n",
        "  epochs = 2\n",
        "  batch_size = 64\n",
        "  input_shape = (28,28,1)\n",
        "  simple_cnn_model = simple_cnn(input_shape)\n",
        "  simple_cnn_model.fit(x_train, y_train, batch_size, epochs, (x_test, y_test))\n",
        "  train_loss, train_accuracy = simple_cnn_model.evaluate(\n",
        "      x_train, y_train, verbose=0)\n",
        "  print('Train data loss:', train_loss)\n",
        "  print('Train data accuracy:', train_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-KZ3Qw57W-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(x_test,y_test):\n",
        "  test_loss, test_accuracy = simple_cnn_model.evaluate(\n",
        "    x_test, y_test, verbose=0)\n",
        "  print('Test data loss:', test_loss)\n",
        "  print('Test data accuracy:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MT-eA1z_fri",
        "colab_type": "code",
        "outputId": "3e4d228d-8f91-402e-c65d-418fd25bbc61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#Let's train our cnn on fashion mnist\n",
        "from keras.datasets import fashion_mnist\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L427aT-a_vsk",
        "colab_type": "code",
        "outputId": "48d02be9-506f-4a90-f1f9-eee9b13e3a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyxGqUJr_y5-",
        "colab_type": "code",
        "outputId": "ee8e01d0-5d1f-41da-c2c9-764423413286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX74DX7w_2ei",
        "colab_type": "code",
        "outputId": "198d3240-e860-4ce4-9153-4d0945d50a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train,y_train,x_test,y_test = pre_process_images(x_train,y_train,x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre_processing_done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP4e8dN7BY_b",
        "colab_type": "code",
        "outputId": "861422bf-3142-4d25-9c5e-603b778486b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWesBHPXAvNW",
        "colab_type": "code",
        "outputId": "5d01e686-e181-4390-a802-6c08c7e08fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "train_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/2\n",
            "Epoch 2/2\n",
            "Train data loss: 0.15943638891180356\n",
            "Train data accuracy: 0.9422333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lomh2xACOry",
        "colab_type": "code",
        "outputId": "6ac21da7-5623-4799-c8d4-1227b92c2475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_model(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data loss: 4.849679325866699\n",
            "Test data accuracy: 0.0562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwMTeq3sC9lC",
        "colab_type": "code",
        "outputId": "3bd714f7-d7f5-47e1-a542-31c2fb812c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        " epochs = 4\n",
        "batch_size = 64\n",
        "input_shape = (28,28,1)\n",
        "simple_cnn_model = simple_cnn(input_shape)\n",
        "simple_cnn_model.fit(x_train, y_train, batch_size, epochs, (x_test, y_test))\n",
        "train_loss, train_accuracy = simple_cnn_model.evaluate(\n",
        "    x_train, y_train, verbose=0)\n",
        "print('Train data loss:', train_loss)\n",
        "print('Train data accuracy:', train_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/4\n",
            "Epoch 2/4\n",
            "Epoch 3/4\n",
            "Epoch 4/4\n",
            "Train data loss: 0.09632884859616558\n",
            "Train data accuracy: 0.96495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnPhogKlDDxI",
        "colab_type": "code",
        "outputId": "23fa9292-17de-4fc2-f602-d26b2075eb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_loss, test_accuracy = simple_cnn_model.evaluate(\n",
        "  x_test, y_test, verbose=0)\n",
        "print('Test data loss:', test_loss)\n",
        "print('Test data accuracy:', test_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test data loss: 0.23022527009993793\n",
            "Test data accuracy: 0.9182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H8Qe_SeBg9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bring data from kaggle\n",
        "!pip install kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V19juDuDfPX",
        "colab_type": "code",
        "outputId": "a164e97e-25ab-4685-9432-96eaf319ccfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install --upgrade kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "670-HiAcB8dF",
        "colab_type": "code",
        "outputId": "87f618f2-8bdc-4d42-ba98-50333069a0d5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2f03d3d2-5980-4dbf-8ca6-a2be2d354e2d\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2f03d3d2-5980-4dbf-8ca6-a2be2d354e2d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 69 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISBnxZz6Jwu9",
        "colab_type": "text"
      },
      "source": [
        "#### Dont' forget to join the competition or click on I understand button in kaggle before downlaoding the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sTc-5qeChnt",
        "colab_type": "code",
        "outputId": "faf5934e-de73-45ba-dd61-d7385af7de43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!kaggle competitions download -c dogs-vs-cats"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test1.zip to /content\n",
            " 95% 257M/271M [00:02<00:00, 97.2MB/s]\n",
            "100% 271M/271M [00:02<00:00, 117MB/s] \n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/86.8k [00:00<?, ?B/s]\n",
            "100% 86.8k/86.8k [00:00<00:00, 86.2MB/s]\n",
            "Downloading train.zip to /content\n",
            " 97% 527M/543M [00:04<00:00, 138MB/s]\n",
            "100% 543M/543M [00:05<00:00, 110MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApZkPriSKjJb",
        "colab_type": "code",
        "outputId": "dd9b9466-b203-4c69-e026-ae5d05b3e75a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data  sampleSubmission.csv  test1.zip  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBHkv8pdCFcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip train.zip\n",
        "!unzip test1.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQN2lqTVKJ12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "work_dir = '/content' # give your correct directory\n",
        "image_names = sorted(os.listdir(os.path.join(work_dir, 'train')))\n",
        "\n",
        "\n",
        "def copy_files(prefix_str, range_start, range_end, target_dir):\n",
        "    image_paths = [os.path.join(work_dir, 'train', prefix_str + '.' + str(i) + '.jpg')\n",
        "                   for i in range(range_start, range_end)]\n",
        "    dest_dir = os.path.join(work_dir, 'new_data', target_dir, prefix_str)\n",
        "    os.makedirs(dest_dir)\n",
        "    for image_path in image_paths:\n",
        "        shutil.copy(image_path, dest_dir)\n",
        "\n",
        "\n",
        "copy_files('dog', 0, 1000, 'train')\n",
        "copy_files('cat', 0, 1000, 'train')\n",
        "copy_files('dog', 1000, 1400, 'test')\n",
        "copy_files('cat', 1000, 1400, 'test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVAayF99LAZg",
        "colab_type": "code",
        "outputId": "a2415a89-64d7-43ab-caad-31c65326d21b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"/content/new_data/train/cat/cat.1.jpg\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAoHBwgHBgoICAgLCgoLDhgQDg0NDh0VFhEYIx8lJCIf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\nLYooouJn/9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECLWptzzU-vG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Benchmarking with simple CNN\n",
        "import os\n",
        "work_dir = \"/content/data\"\n",
        "image_height, image_width = 150, 150\n",
        "train_dir = os.path.join(work_dir,'train')\n",
        "test_dir = os.path.join(work_dir, 'test')\n",
        "no_classes = 2\n",
        "no_validation = 800\n",
        "epochs = 2\n",
        "batch_size = 5\n",
        "no_train = 2000\n",
        "no_test = 800\n",
        "input_shape = (image_height, image_width, 3)\n",
        "epoch_steps = no_train // batch_size\n",
        "test_steps = no_test // batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6SaF03TIcXK",
        "colab_type": "code",
        "outputId": "32eb7529-7c0c-491c-aac0-6e2d8bfe8d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "#fancy way of reading image files and it only loads data in batches so memory efficient too.\n",
        "# important note here is that generatore class expects your folder structure to be in a certain way\n",
        "# data should be present in subfolders of individual class e.g train/dog , train/cat ,test/dog, test/cat\n",
        "import tensorflow as tf\n",
        "generator_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "generator_test = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "\n",
        "train_images = generator_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height))\n",
        "\n",
        "test_images = generator_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaFeGftpJBS3",
        "colab_type": "code",
        "outputId": "196af837-faa1-42fa-aa1d-f23bf623d07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "def simple_cnn(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        activation='relu',\n",
        "        input_shape=input_shape\n",
        "    ))\n",
        "    model.add(tf.keras.layers.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(units=1024, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "    model.add(tf.keras.layers.Dense(units=no_classes, activation='softmax'))\n",
        "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "simple_cnn_model = simple_cnn(input_shape)\n",
        "\n",
        "simple_cnn_model.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch=epoch_steps,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_images,\n",
        "    validation_steps=test_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Epoch 1/2\n",
            "399/400 [============================>.] - ETA: 3s - loss: 0.8801 - acc: 0.4902Epoch 1/2\n",
            "400/400 [==============================] - 1300s 3s/step - loss: 0.8796 - acc: 0.4905 - val_loss: 0.6932 - val_acc: 0.4988\n",
            "Epoch 2/2\n",
            "399/400 [============================>.] - ETA: 3s - loss: 0.6996 - acc: 0.5218Epoch 1/2\n",
            "400/400 [==============================] - 1272s 3s/step - loss: 0.6996 - acc: 0.5215 - val_loss: 0.7028 - val_acc: 0.4963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cfe820400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpsLbja99rfT",
        "colab_type": "code",
        "outputId": "212d3ae6-74b3-42b2-e161-af0a987fbce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#Let's try with bigger batch size\n",
        "work_dir = \"/content/data\"\n",
        "image_height, image_width = 150, 150\n",
        "train_dir = os.path.join(work_dir,'train')\n",
        "test_dir = os.path.join(work_dir, 'test')\n",
        "no_classes = 2\n",
        "no_validation = 800\n",
        "epochs = 2\n",
        "batch_size = 200\n",
        "no_train = 2000\n",
        "no_test = 800\n",
        "input_shape = (image_height, image_width, 3)\n",
        "epoch_steps = no_train // batch_size\n",
        "test_steps = no_test // batch_size\n",
        "\n",
        "#***************************************************\n",
        "import tensorflow as tf\n",
        "generator_train = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "generator_test = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "\n",
        "train_images = generator_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height))\n",
        "\n",
        "test_images = generator_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height))\n",
        "\n",
        "#**************************************************\n",
        "\n",
        "simple_cnn_model.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch=epoch_steps,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_images,\n",
        "    validation_steps=test_steps)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n",
            "Epoch 1/2\n",
            " 9/10 [==========================>...] - ETA: 7s - loss: 0.4996 - acc: 0.7261 Epoch 1/2\n",
            "10/10 [==============================] - 83s 8s/step - loss: 0.4972 - acc: 0.7285 - val_loss: 0.9140 - val_acc: 0.5550\n",
            "Epoch 2/2\n",
            " 9/10 [==========================>...] - ETA: 7s - loss: 0.4316 - acc: 0.7789 Epoch 1/2\n",
            "10/10 [==============================] - 81s 8s/step - loss: 0.4308 - acc: 0.7800 - val_loss: 0.9768 - val_acc: 0.5512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cfe8fa518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLrQzc2iHzTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Trained on 3 different bacth sizes : 10 ,100, 200 and the best val_accuracy achieved is 55% which is not great. May be we can improve this by adding more data or by making more complex network \n",
        "# but let's say we don't have much data and no knowledge on making more complex networks. Transfer learning comes to rescue."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Q8-KJZJUk4",
        "colab_type": "code",
        "outputId": "f229b41e-156c-4a6b-bf79-6ddf33286fe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#Data Augmentation is one of the technique to improve dataset size let's see if data augmentation helps.\n",
        "generator_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3,\n",
        "    shear_range=0.3,)\n",
        "generator_test = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "#*************************************************\n",
        "train_images = generator_train.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height))\n",
        "\n",
        "test_images = generator_test.flow_from_directory(\n",
        "    test_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height))\n",
        "\n",
        "#**************************************************\n",
        "\n",
        "simple_cnn_model.fit_generator(\n",
        "    train_images,\n",
        "    steps_per_epoch=epoch_steps,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_images,\n",
        "    validation_steps=test_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n",
            "Epoch 1/2\n",
            " 9/10 [==========================>...] - ETA: 7s - loss: 0.7855 - acc: 0.5411 Epoch 1/2\n",
            "10/10 [==============================] - 83s 8s/step - loss: 0.7759 - acc: 0.5440 - val_loss: 0.7241 - val_acc: 0.5562\n",
            "Epoch 2/2\n",
            " 9/10 [==========================>...] - ETA: 7s - loss: 0.6967 - acc: 0.5250 Epoch 1/2\n",
            "10/10 [==============================] - 80s 8s/step - loss: 0.6965 - acc: 0.5220 - val_loss: 0.7061 - val_acc: 0.5312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cfe7a32b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc-6gmyyIwmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not much improvement!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F30swSG1LKmw",
        "colab_type": "code",
        "outputId": "8a67740b-0589-4e83-cbee-ccc8c126e0aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Method used below: pass training and testing data to vgg network and extract the output and store is as bottle neck features\n",
        "# Use these bottle neck features as input and train a FCNN \n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "work_dir = '/content/new_data'\n",
        "\n",
        "image_height, image_width = 150, 150\n",
        "train_dir = os.path.join(work_dir, 'train')\n",
        "test_dir = os.path.join(work_dir, 'test')\n",
        "no_classes = 2\n",
        "no_validation = 800\n",
        "epochs = 50\n",
        "batch_size = 50\n",
        "no_train = 2000\n",
        "no_test = 800\n",
        "input_shape = (image_height, image_width, 3)\n",
        "epoch_steps = no_train // batch_size\n",
        "test_steps = no_test // batch_size\n",
        "\n",
        "generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "model = tf.keras.applications.VGG16(include_top=False)\n",
        "\n",
        "train_images = generator.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height),\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "train_bottleneck_features = model.predict_generator(train_images, epoch_steps)\n",
        "print(len(train_bottleneck_features))\n",
        "test_images = generator.flow_from_directory(\n",
        "    test_dir,\n",
        "    batch_size=batch_size,\n",
        "    target_size=(image_width, image_height),\n",
        "    class_mode=None,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_bottleneck_features = model.predict_generator(test_images, test_steps)\n",
        "#print(test_bottleneck_features)\n",
        "train_labels = np.array([0] * int(no_train / 2) + [1] * int(no_train / 2))\n",
        "test_labels = np.array([0] * int(no_test / 2) + [1] * int(no_test / 2))\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten(input_shape=train_bottleneck_features.shape[1:]))\n",
        "model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    train_bottleneck_features,\n",
        "    train_labels,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(test_bottleneck_features, test_labels))\n",
        "\n",
        "model.save_weights(\"/content/top_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "2000\n",
            "Found 800 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 2000 samples, validate on 800 samples\n",
            "Epoch 1/50\n",
            "2000/2000 [==============================] - 2s 777us/sample - loss: 1.8688 - acc: 0.7005 - val_loss: 0.4713 - val_acc: 0.8037\n",
            "Epoch 2/50\n",
            "2000/2000 [==============================] - 1s 563us/sample - loss: 0.5174 - acc: 0.8075 - val_loss: 0.2918 - val_acc: 0.8825\n",
            "Epoch 3/50\n",
            "2000/2000 [==============================] - 1s 575us/sample - loss: 0.3794 - acc: 0.8410 - val_loss: 0.8285 - val_acc: 0.7188\n",
            "Epoch 4/50\n",
            "2000/2000 [==============================] - 1s 542us/sample - loss: 0.3394 - acc: 0.8525 - val_loss: 0.2436 - val_acc: 0.9013\n",
            "Epoch 5/50\n",
            "2000/2000 [==============================] - 1s 529us/sample - loss: 0.2541 - acc: 0.8980 - val_loss: 0.3642 - val_acc: 0.8587\n",
            "Epoch 6/50\n",
            "2000/2000 [==============================] - 1s 549us/sample - loss: 0.2611 - acc: 0.8950 - val_loss: 0.2880 - val_acc: 0.8838\n",
            "Epoch 7/50\n",
            "2000/2000 [==============================] - 1s 560us/sample - loss: 0.2244 - acc: 0.9080 - val_loss: 0.5131 - val_acc: 0.8225\n",
            "Epoch 8/50\n",
            "2000/2000 [==============================] - 1s 562us/sample - loss: 0.1790 - acc: 0.9235 - val_loss: 1.0005 - val_acc: 0.7375\n",
            "Epoch 9/50\n",
            "2000/2000 [==============================] - 1s 546us/sample - loss: 0.1682 - acc: 0.9315 - val_loss: 0.3694 - val_acc: 0.8700\n",
            "Epoch 10/50\n",
            "2000/2000 [==============================] - 1s 555us/sample - loss: 0.1218 - acc: 0.9535 - val_loss: 0.3155 - val_acc: 0.8950\n",
            "Epoch 11/50\n",
            "2000/2000 [==============================] - 1s 554us/sample - loss: 0.1460 - acc: 0.9470 - val_loss: 2.2722 - val_acc: 0.6750\n",
            "Epoch 12/50\n",
            "2000/2000 [==============================] - 1s 540us/sample - loss: 0.1176 - acc: 0.9620 - val_loss: 0.3803 - val_acc: 0.8838\n",
            "Epoch 13/50\n",
            "2000/2000 [==============================] - 1s 554us/sample - loss: 0.1037 - acc: 0.9655 - val_loss: 0.3105 - val_acc: 0.9038\n",
            "Epoch 14/50\n",
            "2000/2000 [==============================] - 1s 536us/sample - loss: 0.1479 - acc: 0.9625 - val_loss: 0.3166 - val_acc: 0.9100\n",
            "Epoch 15/50\n",
            "2000/2000 [==============================] - 1s 539us/sample - loss: 0.0881 - acc: 0.9745 - val_loss: 1.6726 - val_acc: 0.7450\n",
            "Epoch 16/50\n",
            "2000/2000 [==============================] - 1s 542us/sample - loss: 0.0957 - acc: 0.9765 - val_loss: 0.4126 - val_acc: 0.8913\n",
            "Epoch 17/50\n",
            "2000/2000 [==============================] - 1s 559us/sample - loss: 0.0624 - acc: 0.9835 - val_loss: 0.3352 - val_acc: 0.9013\n",
            "Epoch 18/50\n",
            "2000/2000 [==============================] - 1s 560us/sample - loss: 0.0449 - acc: 0.9815 - val_loss: 0.3566 - val_acc: 0.9062\n",
            "Epoch 19/50\n",
            "2000/2000 [==============================] - 1s 540us/sample - loss: 0.0487 - acc: 0.9840 - val_loss: 0.4171 - val_acc: 0.9038\n",
            "Epoch 20/50\n",
            "2000/2000 [==============================] - 1s 540us/sample - loss: 0.0949 - acc: 0.9805 - val_loss: 0.4179 - val_acc: 0.9075\n",
            "Epoch 21/50\n",
            "2000/2000 [==============================] - 1s 537us/sample - loss: 0.0552 - acc: 0.9865 - val_loss: 0.4399 - val_acc: 0.8988\n",
            "Epoch 22/50\n",
            "2000/2000 [==============================] - 1s 613us/sample - loss: 0.0046 - acc: 0.9990 - val_loss: 0.5215 - val_acc: 0.8988\n",
            "Epoch 23/50\n",
            "2000/2000 [==============================] - 1s 607us/sample - loss: 0.1005 - acc: 0.9800 - val_loss: 0.4700 - val_acc: 0.9025\n",
            "Epoch 24/50\n",
            "2000/2000 [==============================] - 1s 652us/sample - loss: 0.1025 - acc: 0.9810 - val_loss: 0.4607 - val_acc: 0.9025\n",
            "Epoch 25/50\n",
            "2000/2000 [==============================] - 1s 627us/sample - loss: 0.0016 - acc: 1.0000 - val_loss: 0.5077 - val_acc: 0.8975\n",
            "Epoch 26/50\n",
            "2000/2000 [==============================] - 1s 620us/sample - loss: 0.1122 - acc: 0.9840 - val_loss: 0.4889 - val_acc: 0.9025\n",
            "Epoch 27/50\n",
            "2000/2000 [==============================] - 1s 633us/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.5971 - val_acc: 0.8988\n",
            "Epoch 28/50\n",
            "2000/2000 [==============================] - 1s 637us/sample - loss: 0.0757 - acc: 0.9900 - val_loss: 0.5099 - val_acc: 0.8988\n",
            "Epoch 29/50\n",
            "2000/2000 [==============================] - 1s 633us/sample - loss: 5.9677e-04 - acc: 1.0000 - val_loss: 0.5452 - val_acc: 0.9000\n",
            "Epoch 30/50\n",
            "2000/2000 [==============================] - 1s 606us/sample - loss: 0.1020 - acc: 0.9860 - val_loss: 0.5175 - val_acc: 0.9025\n",
            "Epoch 31/50\n",
            "2000/2000 [==============================] - 1s 594us/sample - loss: 4.3621e-04 - acc: 1.0000 - val_loss: 0.6256 - val_acc: 0.8963\n",
            "Epoch 32/50\n",
            "2000/2000 [==============================] - 1s 614us/sample - loss: 0.1032 - acc: 0.9835 - val_loss: 0.6199 - val_acc: 0.9038\n",
            "Epoch 33/50\n",
            "2000/2000 [==============================] - 1s 560us/sample - loss: 4.0788e-04 - acc: 1.0000 - val_loss: 0.6061 - val_acc: 0.9062\n",
            "Epoch 34/50\n",
            "2000/2000 [==============================] - 1s 578us/sample - loss: 0.0863 - acc: 0.9885 - val_loss: 0.5856 - val_acc: 0.9062\n",
            "Epoch 35/50\n",
            "2000/2000 [==============================] - 1s 584us/sample - loss: 4.1337e-04 - acc: 1.0000 - val_loss: 0.6075 - val_acc: 0.8963\n",
            "Epoch 36/50\n",
            "2000/2000 [==============================] - 1s 578us/sample - loss: 2.2670e-04 - acc: 1.0000 - val_loss: 0.6253 - val_acc: 0.9025\n",
            "Epoch 37/50\n",
            "2000/2000 [==============================] - 1s 566us/sample - loss: 0.0890 - acc: 0.9895 - val_loss: 0.6521 - val_acc: 0.9038\n",
            "Epoch 38/50\n",
            "2000/2000 [==============================] - 1s 589us/sample - loss: 1.2631e-04 - acc: 1.0000 - val_loss: 0.7181 - val_acc: 0.8963\n",
            "Epoch 39/50\n",
            "2000/2000 [==============================] - 1s 580us/sample - loss: 6.9977e-05 - acc: 1.0000 - val_loss: 0.6852 - val_acc: 0.9062\n",
            "Epoch 40/50\n",
            "2000/2000 [==============================] - 1s 541us/sample - loss: 0.0849 - acc: 0.9900 - val_loss: 0.6413 - val_acc: 0.9000\n",
            "Epoch 41/50\n",
            "2000/2000 [==============================] - 1s 533us/sample - loss: 7.5679e-04 - acc: 1.0000 - val_loss: 0.7081 - val_acc: 0.8963\n",
            "Epoch 42/50\n",
            "2000/2000 [==============================] - 1s 545us/sample - loss: 0.1462 - acc: 0.9835 - val_loss: 0.7195 - val_acc: 0.8963\n",
            "Epoch 43/50\n",
            "2000/2000 [==============================] - 1s 541us/sample - loss: 1.2459e-04 - acc: 1.0000 - val_loss: 0.7058 - val_acc: 0.9038\n",
            "Epoch 44/50\n",
            "2000/2000 [==============================] - 1s 537us/sample - loss: 0.1146 - acc: 0.9860 - val_loss: 0.7085 - val_acc: 0.9000\n",
            "Epoch 45/50\n",
            "2000/2000 [==============================] - 1s 544us/sample - loss: 1.6712e-04 - acc: 1.0000 - val_loss: 0.7145 - val_acc: 0.9050\n",
            "Epoch 46/50\n",
            "2000/2000 [==============================] - 1s 546us/sample - loss: 1.5932e-04 - acc: 1.0000 - val_loss: 0.7316 - val_acc: 0.9075\n",
            "Epoch 47/50\n",
            "2000/2000 [==============================] - 1s 561us/sample - loss: 0.1841 - acc: 0.9800 - val_loss: 0.8702 - val_acc: 0.8813\n",
            "Epoch 48/50\n",
            "2000/2000 [==============================] - 1s 555us/sample - loss: 3.0629e-04 - acc: 1.0000 - val_loss: 0.6504 - val_acc: 0.9100\n",
            "Epoch 49/50\n",
            "2000/2000 [==============================] - 1s 554us/sample - loss: 1.0161e-04 - acc: 1.0000 - val_loss: 0.6648 - val_acc: 0.9150\n",
            "Epoch 50/50\n",
            "2000/2000 [==============================] - 1s 543us/sample - loss: 1.6524e-05 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.9000\n",
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjxR_X1ZJZT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It was giving more than 90% accuracy caompared with our base model accuracy it is very good."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gvvtUfAJlam",
        "colab_type": "code",
        "outputId": "b5ded0d6-8885-4c32-be53-aee830eb0234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "# Method use previous is suitable if you have small dataset but the catch is it may lead to overfitting \n",
        "# Method we are going to use now is to combine vgg with fc and train only the last layers freezing the previous layers of the entire network.\n",
        "import tensorflow as tf\n",
        "input_tensor = tf.keras.layers.Input(shape=(150,150,3))\n",
        "prev_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor)\n",
        "print('Model loaded.')\n",
        "prev_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded.\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLiWnM48dEM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vgg16 has 19 layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlXzJZoTcu7I",
        "colab_type": "code",
        "outputId": "56cf5c81-3006-4ba1-dc53-9d827aba3db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(prev_model.layers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9lGUdvwYOit",
        "colab_type": "code",
        "outputId": "42c96fd1-7564-451f-efdf-0d7a3e98d647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "prev_model.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fe0c60905c0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c60fc1d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c5fdec50>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c600e0b8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c4794ba8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c479ca90>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c47ad0f0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47ad128>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47babe0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47cd240>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c4759860>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c4759898>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c476d3c8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47779e8>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c478c048>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c478c080>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c4719b70>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c472b1d0>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c4738828>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQxoNDaJw09-",
        "colab_type": "code",
        "outputId": "f56dd497-d2ff-4c9e-c51c-ca7cde60487a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# build a classifier model to put on top of the convolutional model\n",
        "top_model = tf.keras.models.Sequential()\n",
        "top_model.add(tf.keras.layers.Flatten(input_shape = prev_model.output_shape[1:]))\n",
        "top_model.add(tf.keras.layers.Dense(1024, activation='relu'))\n",
        "top_model.add(tf.keras.layers.Dropout(0.3))\n",
        "top_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "top_model.load_weights('/content/top_model.h5')\n",
        "top_model.summary()\n",
        "top_model.layers\n",
        "len(top_model.layers)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1024)              8389632   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 8,390,657\n",
            "Trainable params: 8,390,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFMuEv6YdPLi",
        "colab_type": "code",
        "outputId": "f1658df7-17c7-4c96-fa60-cfb8337c2191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "#concatenating vgg16 with our custom fcnn\n",
        "\n",
        "new_model = tf.keras.models.Sequential()\n",
        "for l in prev_model.layers:\n",
        "    new_model.add(l)\n",
        "\n",
        "new_model.add(top_model)\n",
        "\n",
        "print(new_model.layers)\n",
        "new_model.summary()\n",
        "print(len(new_model.layers))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c60fc1d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c5fdec50>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fe0c600e0b8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c4794ba8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c479ca90>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fe0c47ad0f0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c47ad128>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c47babe0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c47cd240>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fe0c4759860>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c4759898>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c476d3c8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c47779e8>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fe0c478c048>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c478c080>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c4719b70>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fe0c472b1d0>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fe0c4738828>, <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fe0c3b28048>]\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 1)                 8390657   \n",
            "=================================================================\n",
            "Total params: 23,105,345\n",
            "Trainable params: 23,105,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8I7a97caIep",
        "colab_type": "code",
        "outputId": "eae98f34-7eb9-4950-9acd-0dabe890495b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "new_model.layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c60fc1d0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c5fdec50>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c600e0b8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c4794ba8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c479ca90>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c47ad0f0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47ad128>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47babe0>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47cd240>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c4759860>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c4759898>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c476d3c8>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c47779e8>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c478c048>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c478c080>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c4719b70>,\n",
              " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fe0c472b1d0>,\n",
              " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fe0c4738828>,\n",
              " <tensorflow.python.keras.engine.sequential.Sequential at 0x7fe0c3b28048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRr0m5sOZSXO",
        "colab_type": "code",
        "outputId": "08a0d1ef-47ac-458c-d06f-4cc88cf6767e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#idea here is to train the last convolutional block and customm fcnn\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in new_model.layers[:14]:\n",
        "    layer.trainable = False\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "new_model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "#setting some parameters\n",
        "\n",
        "work_dir = '/content/new_data'\n",
        "\n",
        "img_height, img_width = 150, 150\n",
        "train_dir = os.path.join(work_dir, 'train')\n",
        "test_dir = os.path.join(work_dir, 'test')\n",
        "no_classes = 2\n",
        "no_validation = 800\n",
        "epochs = 50\n",
        "batch_size = 50\n",
        "no_train = 2000\n",
        "no_test = 800\n",
        "input_shape = (img_height, img_width, 3)\n",
        "epoch_steps = no_train // batch_size\n",
        "test_steps = no_test // batch_size\n",
        "\n",
        "\n",
        "#train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "# fine-tune the model\n",
        "new_model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=epoch_steps,\n",
        "    epochs=epochs,\n",
        "    validation_data= test_generator,\n",
        "    validation_steps=test_steps) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n",
            "Epoch 1/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 5.2537 - acc: 0.4990Epoch 1/50\n",
            "40/40 [==============================] - 49s 1s/step - loss: 5.1392 - acc: 0.5020 - val_loss: 0.6928 - val_acc: 0.5200\n",
            "Epoch 2/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6837 - acc: 0.5518Epoch 1/50\n",
            "40/40 [==============================] - 47s 1s/step - loss: 0.6837 - acc: 0.5510 - val_loss: 0.6769 - val_acc: 0.5800\n",
            "Epoch 3/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6711 - acc: 0.5903Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.6704 - acc: 0.5920 - val_loss: 0.6619 - val_acc: 0.6300\n",
            "Epoch 4/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6526 - acc: 0.6205Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.6515 - acc: 0.6220 - val_loss: 0.6414 - val_acc: 0.6700\n",
            "Epoch 5/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6403 - acc: 0.6492Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.6402 - acc: 0.6495 - val_loss: 0.6210 - val_acc: 0.7088\n",
            "Epoch 6/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6216 - acc: 0.6733Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.6215 - acc: 0.6745 - val_loss: 0.5996 - val_acc: 0.7437\n",
            "Epoch 7/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.6053 - acc: 0.6949Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.6045 - acc: 0.6940 - val_loss: 0.5792 - val_acc: 0.7325\n",
            "Epoch 8/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5849 - acc: 0.7123Epoch 1/50\n",
            "40/40 [==============================] - 47s 1s/step - loss: 0.5862 - acc: 0.7115 - val_loss: 0.5448 - val_acc: 0.7825\n",
            "Epoch 9/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5629 - acc: 0.7256Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.5621 - acc: 0.7260 - val_loss: 0.5164 - val_acc: 0.8012\n",
            "Epoch 10/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5349 - acc: 0.7559Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.5347 - acc: 0.7555 - val_loss: 0.4860 - val_acc: 0.8325\n",
            "Epoch 11/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.5019 - acc: 0.7738Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.5011 - acc: 0.7750 - val_loss: 0.4477 - val_acc: 0.8350\n",
            "Epoch 12/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.7841Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.4799 - acc: 0.7865 - val_loss: 0.4188 - val_acc: 0.8388\n",
            "Epoch 13/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8056Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.4504 - acc: 0.8050 - val_loss: 0.3870 - val_acc: 0.8525\n",
            "Epoch 14/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4394 - acc: 0.8036Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.4382 - acc: 0.8050 - val_loss: 0.3626 - val_acc: 0.8650\n",
            "Epoch 15/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.4100 - acc: 0.8215Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.4095 - acc: 0.8215 - val_loss: 0.3384 - val_acc: 0.8700\n",
            "Epoch 16/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3775 - acc: 0.8308Epoch 1/50\n",
            "40/40 [==============================] - 48s 1s/step - loss: 0.3771 - acc: 0.8325 - val_loss: 0.3173 - val_acc: 0.8750\n",
            "Epoch 17/50\n",
            "39/40 [============================>.] - ETA: 0s - loss: 0.3669 - acc: 0.8492Epoch 1/50\n",
            "40/40 [==============================] - 52s 1s/step - loss: 0.3694 - acc: 0.8485 - val_loss: 0.3446 - val_acc: 0.8512\n",
            "Epoch 18/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.3532 - acc: 0.8446Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.3520 - acc: 0.8455 - val_loss: 0.2921 - val_acc: 0.8825\n",
            "Epoch 19/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.3218 - acc: 0.8656Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.3227 - acc: 0.8655 - val_loss: 0.2735 - val_acc: 0.8925\n",
            "Epoch 20/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.3095 - acc: 0.8692Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.3086 - acc: 0.8695 - val_loss: 0.2602 - val_acc: 0.8938\n",
            "Epoch 21/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.3015 - acc: 0.8703Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.3041 - acc: 0.8695 - val_loss: 0.2513 - val_acc: 0.8950\n",
            "Epoch 22/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2952 - acc: 0.8692Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2919 - acc: 0.8715 - val_loss: 0.2445 - val_acc: 0.9038\n",
            "Epoch 23/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2959 - acc: 0.8795Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2964 - acc: 0.8785 - val_loss: 0.2733 - val_acc: 0.8838\n",
            "Epoch 24/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2775 - acc: 0.8872Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.2780 - acc: 0.8865 - val_loss: 0.2452 - val_acc: 0.8963\n",
            "Epoch 25/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2804 - acc: 0.8733Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2796 - acc: 0.8755 - val_loss: 0.2435 - val_acc: 0.8950\n",
            "Epoch 26/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2705 - acc: 0.8846Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.2708 - acc: 0.8840 - val_loss: 0.2288 - val_acc: 0.9050\n",
            "Epoch 27/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2504 - acc: 0.8974Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.2518 - acc: 0.8955 - val_loss: 0.2360 - val_acc: 0.9075\n",
            "Epoch 28/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2677 - acc: 0.8928Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.2660 - acc: 0.8930 - val_loss: 0.2312 - val_acc: 0.9062\n",
            "Epoch 29/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2491 - acc: 0.8985Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.2473 - acc: 0.8995 - val_loss: 0.2353 - val_acc: 0.9000\n",
            "Epoch 30/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2439 - acc: 0.8933Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.2428 - acc: 0.8945 - val_loss: 0.2185 - val_acc: 0.9050\n",
            "Epoch 31/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2446 - acc: 0.8949Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2452 - acc: 0.8950 - val_loss: 0.2114 - val_acc: 0.9087\n",
            "Epoch 32/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2354 - acc: 0.9041Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.2373 - acc: 0.9035 - val_loss: 0.2612 - val_acc: 0.8900\n",
            "Epoch 33/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2366 - acc: 0.9021Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2354 - acc: 0.9030 - val_loss: 0.2396 - val_acc: 0.8988\n",
            "Epoch 34/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2298 - acc: 0.9108Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.2296 - acc: 0.9100 - val_loss: 0.2214 - val_acc: 0.9075\n",
            "Epoch 35/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2046 - acc: 0.9236Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2063 - acc: 0.9235 - val_loss: 0.2280 - val_acc: 0.9075\n",
            "Epoch 36/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2243 - acc: 0.9026Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.2254 - acc: 0.9030 - val_loss: 0.2043 - val_acc: 0.9162\n",
            "Epoch 37/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2147 - acc: 0.9149Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.2166 - acc: 0.9140 - val_loss: 0.2209 - val_acc: 0.9075\n",
            "Epoch 38/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2039 - acc: 0.9200Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.2046 - acc: 0.9195 - val_loss: 0.2039 - val_acc: 0.9187\n",
            "Epoch 39/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1956 - acc: 0.9303Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.1961 - acc: 0.9300 - val_loss: 0.2028 - val_acc: 0.9175\n",
            "Epoch 40/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2001 - acc: 0.9133Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2003 - acc: 0.9130 - val_loss: 0.2182 - val_acc: 0.9100\n",
            "Epoch 41/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2002 - acc: 0.9174Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.2022 - acc: 0.9165 - val_loss: 0.2042 - val_acc: 0.9137\n",
            "Epoch 42/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.2038 - acc: 0.9133Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.2056 - acc: 0.9125 - val_loss: 0.1984 - val_acc: 0.9100\n",
            "Epoch 43/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1927 - acc: 0.9205Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.1944 - acc: 0.9200 - val_loss: 0.2045 - val_acc: 0.9175\n",
            "Epoch 44/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1840 - acc: 0.9282Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.1832 - acc: 0.9290 - val_loss: 0.1975 - val_acc: 0.9150\n",
            "Epoch 45/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1725 - acc: 0.9323Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.1750 - acc: 0.9315 - val_loss: 0.2061 - val_acc: 0.9137\n",
            "Epoch 46/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1860 - acc: 0.9215Epoch 1/50\n",
            "40/40 [==============================] - 54s 1s/step - loss: 0.1848 - acc: 0.9220 - val_loss: 0.1954 - val_acc: 0.9175\n",
            "Epoch 47/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1839 - acc: 0.9226Epoch 1/50\n",
            "40/40 [==============================] - 53s 1s/step - loss: 0.1821 - acc: 0.9230 - val_loss: 0.2129 - val_acc: 0.9137\n",
            "Epoch 48/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1706 - acc: 0.9318Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.1712 - acc: 0.9315 - val_loss: 0.1956 - val_acc: 0.9162\n",
            "Epoch 49/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1757 - acc: 0.9308Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.1783 - acc: 0.9295 - val_loss: 0.1890 - val_acc: 0.9162\n",
            "Epoch 50/50\n",
            "39/40 [============================>.] - ETA: 1s - loss: 0.1622 - acc: 0.9395Epoch 1/50\n",
            "40/40 [==============================] - 55s 1s/step - loss: 0.1627 - acc: 0.9395 - val_loss: 0.2017 - val_acc: 0.9187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe0c36f2ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV38lNZkuEIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# as we can see the validation accuracy improved a bit by using this method of training.\n",
        "#This approach works better when the given problem is very different from the images that the model is trained upon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Kv350EuGHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Size\t    Similar Dataset\t            Different Dataset\n",
        "# Smaller data\tFine-tune the output layers\tFine-tune the deeper layer\n",
        "# Bigger data\t  Fine-tune the whole model\t  Train from scratch"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}